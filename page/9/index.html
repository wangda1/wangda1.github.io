<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="千淘万漉虽辛苦，吹尽黄沙始到金">
<meta property="og:type" content="website">
<meta property="og:title" content="笔记记录">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;page&#x2F;9&#x2F;index.html">
<meta property="og:site_name" content="笔记记录">
<meta property="og:description" content="千淘万漉虽辛苦，吹尽黄沙始到金">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/9/"/>





  <title>笔记记录</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">笔记记录</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" target="_blank" rel="noopener" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/05/Algorithm/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/05/Algorithm/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" itemprop="url">遗传算法</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-05T16:03:25+08:00">
                2020-01-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Algorithm/" itemprop="url" rel="index">
                    <span itemprop="name">Algorithm</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="优化问题（一）遗传算法"><a href="#优化问题（一）遗传算法" class="headerlink" title="优化问题（一）遗传算法"></a>优化问题（一）遗传算法</h1><blockquote>
<p>遗传算法（Genetic Algorithm, GA）起源于对生物系统所进行的计算机模拟研究。它是模仿自然界生物进化机制发展起来的随机全局搜索和优化方法，借鉴了达尔文的进化论和孟德尔的遗传学说。其本质是一种高效、并行、全局搜索的方法，能在搜索过程中自动获取和积累有关搜索空间的知识，并自适应地控制搜索过程以求得最佳解。</p>
</blockquote>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>遗传算法是以面为单位的搜索，比以点为单位的搜索，更能发现全局最优解。</strong></p>
<p><img src="/2020/01/05/Algorithm/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/genetic_algorithm_process.jpeg" alt="process"></p>
<h2 id="验证函数"><a href="#验证函数" class="headerlink" title="验证函数"></a>验证函数</h2><p>$$f(x)=xsin(10\pi x)+2$$</p>
<h2 id="遗传算法的几个重要步骤"><a href="#遗传算法的几个重要步骤" class="headerlink" title="遗传算法的几个重要步骤"></a>遗传算法的几个重要步骤</h2><h3 id="1-基因的编码"><a href="#1-基因的编码" class="headerlink" title="1. 基因的编码"></a>1. 基因的编码</h3><p>编码的主要目的是为后期的遗传变异建立基础。</p>
<p><img src="/2020/01/05/Algorithm/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/genetic_algorithm.png" alt="code"></p>
<p>1.1 基因的编码方式</p>
<ul>
<li>二进制编码</li>
<li>浮点数编码</li>
</ul>
<p>在我们常用的问题中，基因型–编码；表现型–坐标；我们只需要在相应的坐标精度下使用一种编码表方式将坐标编码出来。</p>
<h3 id="2-适应性评价与选择函数"><a href="#2-适应性评价与选择函数" class="headerlink" title="2. 适应性评价与选择函数"></a>2. 适应性评价与选择函数</h3><p>这里是对个体的评价和选择的过程，也是对搜索空间的修剪。</p>
<p>2.1 适应度函数（fitness function）— 目标函数</p>
<p>适应度函数即是衡量该基因型的个体对环境的适应度评估标准。它是我们作为选择函数选择的依据。我们可以很明显地以<strong>目标函数</strong>作为我们的适应度函数</p>
<p>2.2 选择函数（selection）</p>
<p><em>为什么这里会出现选择函数而不是直接对适应度最高的函数进行选择呢？</em></p>
<p>模拟生物界的遗传进化规律，并不是所有的优良个体都会被保存，也不是所有的劣势个体都会被淘汰。</p>
<p>常用方法：</p>
<ul>
<li>轮盘赌（Roulette Wheel Selection）</li>
</ul>
<p><em>转盘游戏</em></p>
<p><img src="/2020/01/05/Algorithm/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/roulette_wheel_selection.png" alt="roulette_wheel"></p>
<h3 id="3-基因重组与基因突变"><a href="#3-基因重组与基因突变" class="headerlink" title="3. 基因重组与基因突变"></a>3. 基因重组与基因突变</h3><p>这部分是对搜索空间的扩大，通过对个体进行变异从而得到更多基因型和表现型的个体，这部分会有大量的随机操作</p>
<p>3.1 基因重组</p>
<p>通过对两个基因的编码进行部分替换得到</p>
<p><img src="/2020/01/05/Algorithm/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/ga_ge_reconstruct.png" alt="ge_reconstruct"></p>
<p>3.2 基因突变</p>
<p>对单个个体的基因型进行改变</p>
<ul>
<li>二进制的编码： <code>0</code> 与 <code>1</code> 之间的互换</li>
<li>浮点数的编码：对浮点数增加/减少一个随机数</li>
</ul>
<h3 id="4-遗传算子总结"><a href="#4-遗传算子总结" class="headerlink" title="4. 遗传算子总结"></a>4. 遗传算子总结</h3><p><img src="/2020/01/05/Algorithm/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/ga_operator.png" alt="ga_operator"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://blog.csdn.net/u010451580/article/details/51178225" target="_blank" rel="noopener">遗传算法详解</a></li>
<li><a href="https://blog.csdn.net/zzzzjh/article/details/80633573" target="_blank" rel="noopener">遗传算法python实现</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/05/Something/use-hexo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/05/Something/use-hexo/" itemprop="url">use-hexo</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-05T12:20:12+08:00">
                2020-01-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Something/" itemprop="url" rel="index">
                    <span itemprop="name">Something</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="USE-HEXO"><a href="#USE-HEXO" class="headerlink" title="USE-HEXO"></a>USE-HEXO</h1><p>本篇记录将 Blogs 使用 hexo + Next 主题的过程。</p>
<h2 id="1-HEXO"><a href="#1-HEXO" class="headerlink" title="1. HEXO"></a>1. HEXO</h2><blockquote>
<p>Hexo 是高效的静态站点生成框架，基于 Node.js.</p>
</blockquote>
<h3 id="1-1-安装"><a href="#1-1-安装" class="headerlink" title="1.1 安装"></a>1.1 安装</h3><p><code>npm i hexo-cli -g</code></p>
<p>配置 github，文件：<code>_config.yml</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: https://github.com/godweiyang/godweiyang.github.io</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>

<h3 id="1-2-常用命令"><a href="#1-2-常用命令" class="headerlink" title="1.2 常用命令"></a>1.2 常用命令</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化文件夹</span></span><br><span class="line">hexo init</span><br><span class="line"><span class="comment"># 生成静态网页</span></span><br><span class="line">hexo g</span><br><span class="line"><span class="comment"># 打开本地服务器</span></span><br><span class="line">hexo s</span><br><span class="line">hexo s --debug</span><br><span class="line"><span class="comment"># 新建文章</span></span><br><span class="line">hexo new post <span class="string">"article title"</span></span><br><span class="line"><span class="comment"># 新建页面</span></span><br><span class="line">hexo new page <span class="string">"page title"</span></span><br><span class="line"><span class="comment"># 新建草稿</span></span><br><span class="line">hexo new draft <span class="string">"draft title"</span></span><br><span class="line"><span class="comment"># 部署到github</span></span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>

<h3 id="1-3-集成主题-next"><a href="#1-3-集成主题-next" class="headerlink" title="1.3 集成主题 next"></a>1.3 集成主题 <code>next</code></h3><ul>
<li>关于 Next 主题的配置可以参考官方文档 <a href="http://theme-next.iissnan.com/getting-started.html" target="_blank" rel="noopener">NexT</a></li>
</ul>
<p>本站的配置内容（<code>blog-hexo\themes\next\themes\next</code>）：</p>
<ul>
<li>menu</li>
<li>scheme</li>
<li>social</li>
<li>tencent_analytics</li>
<li>Reward</li>
<li>since</li>
</ul>
<h3 id="1-4-文章模板"><a href="#1-4-文章模板" class="headerlink" title="1.4 文章模板"></a>1.4 文章模板</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line"># 文章标题中的空格替换为-</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line"># hexo 支持多个并列 tag</span><br><span class="line">tags:</span><br><span class="line">- A</span><br><span class="line">- B</span><br><span class="line"># hexo 不支持多个并列 category，以下为顺序父子关系</span><br><span class="line">categories:</span><br><span class="line">- A</span><br><span class="line">- B</span><br><span class="line">description:</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<h3 id="1-5-写文章注意事项"><a href="#1-5-写文章注意事项" class="headerlink" title="1.5 写文章注意事项"></a>1.5 写文章注意事项</h3><p><code>next</code> 能自动识别不同级别的标题</p>
<h2 id="2-本站文章的更新"><a href="#2-本站文章的更新" class="headerlink" title="2. 本站文章的更新"></a>2. 本站文章的更新</h2><p>本站文章的更新采取了 Blog 源文件目录与 hexo 生成的目录分别放置的方式，每次站点的更新需要：</p>
<ol>
<li>将所有的 blog 文件复制到 <code>blog-hexo/source/_posts</code> 目录下；</li>
<li><code>hexo s -g</code> 提前预览更新，或直接 <code>hexo g</code> 生成静态文件目录；</li>
<li>将 <code>blog-hexo/public</code> 目录中的所有内容粘贴至 git 目录中，<code>add-&gt;commit-&gt;push</code> 即可；（这里<code>git push -f</code>）</li>
<li>将 github 中的 <code>Custom domain</code> 设置为自身的域名 <code>laoxiangchun.cn</code></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/05/about/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/05/about/" itemprop="url">about</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-05T11:07:10+08:00">
                2020-01-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<p>title: about<br>date: 2020-01-05 11:07:10<br>tags:</p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/04/NLP/Bert_ELMO_GPT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/04/NLP/Bert_ELMO_GPT/" itemprop="url">Bert_ELMO_GPT</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-04T22:57:35+08:00">
                2020-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Introduction-of-Bert-ELMO-GPT"><a href="#Introduction-of-Bert-ELMO-GPT" class="headerlink" title="Introduction of Bert, ELMO, GPT"></a>Introduction of Bert, ELMO, GPT</h1><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><ul>
<li>传统的 encoding 方式</li>
<li>现在的 word embedding 的几种方式</li>
</ul>
<h2 id="1-传统的-encoding-方式"><a href="#1-传统的-encoding-方式" class="headerlink" title="1. 传统的 encoding 方式"></a>1. 传统的 encoding 方式</h2><ul>
<li><p>1-of-N encoding</p>
<p>  one hot 的方式，但缺乏词汇之间的语义相似度</p>
</li>
<li><p>word embedding</p>
<p>  refer: <a href="https://www.youtube.com/watch?v=X7PH3NuYW0Q" target="_blank" rel="noopener">https://www.youtube.com/watch?v=X7PH3NuYW0Q</a></p>
</li>
</ul>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/word2com_1.png" alt="word2com"></p>
<p><em>In the typical embedding, the same type hase the same embedding.</em></p>
<p><strong>首先明确：下图中的 word， 属于相同的 type，但是不同的 token</strong></p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/word2com_2.png" alt="word2com"></p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/word2com_3.png" alt="word2com"></p>
<p><em>Motivaton:</em> 那怎么做才能让language 在不同的 context 中，根据不同的 token拥有不同的 word embedding 呢？，一下介绍几种常见的 model</p>
<h2 id="2-ELMO"><a href="#2-ELMO" class="headerlink" title="2. ELMO"></a>2. ELMO</h2><p>Embeddings from Language Model (ELMO)</p>
<h3 id="2-1-RNN-based-ELMO"><a href="#2-1-RNN-based-ELMO" class="headerlink" title="2.1 RNN-based ELMO"></a>2.1 RNN-based ELMO</h3><ul>
<li>RNN-based language model</li>
<li>不需要标注数据，直接 trainning</li>
</ul>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/word2com_4.png" alt="elmo"></p>
<p>对于每个 input 的 hidden ，都可以代表该 token 在 context 中的 embedding，因为在不同的语境中，虽然是相同的 type， 但 token 的不同能产生不同的 embedding</p>
<h3 id="2-2-LSTM-based-ELMO"><a href="#2-2-LSTM-based-ELMO" class="headerlink" title="2.2 LSTM-based ELMO"></a>2.2 LSTM-based ELMO</h3><ul>
<li>考虑进正向及反向的 contex 信息</li>
</ul>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/word2com_5.png" alt="elmo"></p>
<ul>
<li>how to choose hidden layer?</li>
</ul>
<p>当深度的 LSTM 进行训练的时候，train 得到的有很多 layer 的 hidden ，如何选取不同的 hidden layer作为 output 呢？？</p>
<p>ELMO says, utilize all!</p>
<ul>
<li>how to train ?</li>
</ul>
<p>进行 weight sum，这里的 weight 是 α1，α2，α3…，表示出 deep RNN中 hidden layer 的 weight，这里把 α1，α2…当做 parameter 与 down stream 的 task 接起来一起 train！！</p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/word2com_6.png" alt="elmo"></p>
<p>在上图中可以看出，down stream 的 tasks 的不同， train 出来的不同 hidden layer 的 weight 也不同，是与 down stream tasks 紧密相关的。</p>
<ul>
<li>SRL: Semantic Role Labelling</li>
<li>Coref: co-reference …</li>
</ul>
<h2 id="3-BERT"><a href="#3-BERT" class="headerlink" title="3. BERT"></a>3. BERT</h2><p><strong>Encoder of Transformer</strong></p>
<p>BERT 是 transformer 的 encoder，相比于前面的 transformer 需要大量的 annotation text， <em>Bert 不需要 annotation text</em>，train 之后的 model，输入 word 输出 embedding. Bert 的内部并不是 RNN，而是 self-attention 的 transformer 的 encoder.</p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/word2com_7.png" alt="bert"></p>
<p><em>在中文中，也许使用 character 更为有效，因为中文中的词（word）是无穷无尽的，字（character）是有限的</em></p>
<h3 id="3-1-Training-of-Bert"><a href="#3-1-Training-of-Bert" class="headerlink" title="3.1 Training of Bert"></a>3.1 Training of Bert</h3><p><strong>How to train Bert network?</strong></p>
<ul>
<li>Approach 1: Masked LM</li>
</ul>
<ol>
<li>input 的 word 会有 15% 被替换为一个特殊的 token，即 mask；</li>
<li>Bert 的 train goal 是把 mask 的 token 补充回来</li>
</ol>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert2.png" alt="bert_2"></p>
<p>当使用 Linear Multi-class Classifier做分类任务时，可能需要很多层的 Bert 用来 representation. 并且由此也可以看出当两个 word 填到一个 mask ，没有违和感则说明两个 word 有相似的 semantic</p>
<ul>
<li>Approach 2: Next Sentence Prediction</li>
</ul>
<p><em>Train goal:</em> next sentence prediction.</p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert_3.png" alt="bert_3"></p>
<ul>
<li>SEP: 代表了两个句子的分界点</li>
<li>CLS：代表了 Bert 的分类结果输出点，当 Bert 判断两个句子应当相接，CLS 输出 yes，否则输出 no.</li>
</ul>
<blockquote>
<p>当 Bert 同时使用者两个 tasks 进行 train 的的时候，learn 的效果最好！！</p>
</blockquote>
<h3 id="3-2-How-to-use-Bert"><a href="#3-2-How-to-use-Bert" class="headerlink" title="3.2 How to use Bert"></a>3.2 How to use Bert</h3><p>最直接的想法是用 Bert 当作抽 feature 的工具，利用 Bert 输出的 word embedding进行 down stream tasks 的 训练。一下所有 tasks 的训练不同于上述中 Bert 的训练，下面的 task 属于 down streeam tasks of Bert，需要 labelled data.</p>
<ul>
<li>把 bert 的训练和下游的任务放在一起进行 train</li>
</ul>
<h4 id="case1-Sequence-gt-class-分类任务"><a href="#case1-Sequence-gt-class-分类任务" class="headerlink" title="case1: Sequence -&gt; class 分类任务"></a>case1: Sequence -&gt; class 分类任务</h4><p>在开头的地方给一个分类的符号，再通过 接一个 linear classifier 进行分类，</p>
<p>Model:</p>
<ul>
<li>Bert + Linear Classifier for CLS position</li>
<li>Input: single sentence</li>
<li>Output: class</li>
<li>Example: Sentiment Analysis …</li>
</ul>
<p>Train：</p>
<ul>
<li>Linear Classifier: Trained from scratch</li>
<li>Bert: fine-tune</li>
<li>model 需要学习到的参数的数量还是比较少的</li>
</ul>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert_4.png" alt="bert4"></p>
<h4 id="case2-sentences’-word-slot"><a href="#case2-sentences’-word-slot" class="headerlink" title="case2: sentences’ word slot"></a>case2: sentences’ word slot</h4><p>句子的词分类问题，将句子中的每个词填入一个class slot</p>
<p>Model:</p>
<ul>
<li>Bert + Linear Classifier for each embedding position</li>
<li>Input: single sentence</li>
<li>Output: class of each word</li>
<li>Example: Slot filling</li>
</ul>
<p>Train:</p>
<ul>
<li>同上</li>
</ul>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert_5.png" alt="bert_case_2"></p>
<h4 id="case3-premise-gt-判断-hypothesis"><a href="#case3-premise-gt-判断-hypothesis" class="headerlink" title="case3: premise -&gt; 判断 hypothesis"></a>case3: premise -&gt; 判断 hypothesis</h4><p>输入两个句子，一个作为 premise，一个作为 hypothesis，判断是否正确：T/F/unknown</p>
<p>Model:</p>
<ul>
<li>Bert + Linear Classifier for CLS position</li>
<li>Input: two sentences</li>
<li>Output: class</li>
<li>Example: Natural Language Inference</li>
</ul>
<p>Train:</p>
<ul>
<li>同上</li>
</ul>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert_6.png" alt="bert_case_3"></p>
<h4 id="case4-Extraction-based-QA"><a href="#case4-Extraction-based-QA" class="headerlink" title="case4: Extraction-based QA"></a>case4: Extraction-based QA</h4><p>主要的任务是给 model 一篇文章和几个问题，model 能够正确地回答问题（Extraction-based Question Answering(QA) E.g. SQuAD）</p>
<p>Model:</p>
<ul>
<li>Bert + s-vector + e-vector，通过 s-vector, e-vector 与 word embedding做 dot product — softmax 得到分数；</li>
<li>Input: questions + documents</li>
<li>Output: integers: s, e</li>
<li>Example: Extraction-based Question Answering(QA) E.g. SQuAD</li>
</ul>
<p>Train:</p>
<ul>
<li>同上</li>
</ul>
<p>对这种任务进行解释：这种是 Extraction-style，只能在原文中找答案</p>
<ul>
<li>输入：Document D = {d1, d2, … dn}，Query Q = {q1, q2, q3 …}</li>
<li>输出：two integers（s, e), 两个 position 的标记， Answer: A = {ds,…,de}</li>
</ul>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert_7.png" alt="bert_case_4"></p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert_8.png" alt="bert_case_4"></p>
<h3 id="3-3-中文版本的-bert-–-Erine"><a href="#3-3-中文版本的-bert-–-Erine" class="headerlink" title="3.3 中文版本的 bert – Erine"></a>3.3 中文版本的 bert – Erine</h3><p>这里在对 Bert 进行训练的时候不同于 以上 Bert mask LM 方法中对 character 进行 mask，这里是对 word 进行 mask。</p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/erine.png" alt="erine"></p>
<h3 id="3-4-What-bert-learns"><a href="#3-4-What-bert-learns" class="headerlink" title="3.4 What bert learns?"></a>3.4 What bert learns?</h3><p>研究者通过将 bert 24层的 embedding 输出对比（这个过程是类似于 ELMO 的 weigt sum 方式，抽出 Bert 的 24 层的 hidden layer， 进行 weight sum 并与 down stream task 一起 train 发现， bert 的24层从低到高学习到了 NLP 的大部分过程：<code>one Bert = 文法-&gt;句法-&gt;语义</code></p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert_9.png" alt="bert_9"></p>
<blockquote>
<p>图中横坐标代表 Bert 的24层的 representations，颜色越深代表该 task 利用该部分的 representation 越大。</p>
</blockquote>
<h3 id="3-5-Multilingual-Bert"><a href="#3-5-Multilingual-Bert" class="headerlink" title="3.5 Multilingual Bert"></a>3.5 Multilingual Bert</h3><p>多语言的 bert，google 的研究者爬取104种语言的 wiki进行训练 多语言版本的 bert</p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/bert_10.png" alt="bert_10"></p>
<h2 id="4-GPT"><a href="#4-GPT" class="headerlink" title="4. GPT"></a>4. GPT</h2><p><strong>Generative Pre-Training</strong><br>特别大特别大的一个预训练模型</p>
<p><em>GPT 是 transformer 的 decoder</em>，由 openAI 制作</p>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/gpt_1.png" alt="GPT"></p>
<p>GPT-2 model 特别巨大，能够在<strong>没有训练资料</strong>的情况下，做：</p>
<ul>
<li>Reading Comprehension</li>
<li>Summarization</li>
<li>Translation</li>
</ul>
<p><img src="/2020/01/04/NLP/Bert_ELMO_GPT/gtp_2.png" alt="gpt_2"></p>
<p>GPT-2 OpenAI 最大的model 拥有的参数有 1542M，但考虑到到多种问题并没有被 release，release 的 model 的版本与 bert 差不多.</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><ul>
<li><a href="https://talktotransformer.com/" target="_blank" rel="noopener">https://talktotransformer.com/</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/04/NLP/Transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/04/NLP/Transformer/" itemprop="url">Transformer</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-04T22:55:12+08:00">
                2020-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p>reference: <a href="https://www.youtube.com/watch?v=ugWDIIOHtPA" target="_blank" rel="noopener">https://www.youtube.com/watch?v=ugWDIIOHtPA</a></p>
<p>Seq2Seq model with self-attention</p>
<h2 id="Backgroud"><a href="#Backgroud" class="headerlink" title="Backgroud"></a>Backgroud</h2><p>RNN: Hard to parallel,  </p>
<h3 id="1-Use-CNN-to-replace-RNN"><a href="#1-Use-CNN-to-replace-RNN" class="headerlink" title="1. Use CNN to replace RNN"></a>1. Use CNN to replace RNN</h3><p><img src="/2020/01/04/NLP/Transformer/transformer1.png" alt="RNN&amp;CNN"></p>
<p><img src="/2020/01/04/NLP/Transformer/transformer2.png" alt="RNN&amp;CNN"></p>
<h3 id="2-Self-attention"><a href="#2-Self-attention" class="headerlink" title="2. Self-attention"></a>2. Self-attention</h3><p><img src="/2020/01/04/NLP/Transformer/transformer3.png" alt="self-attention"></p>
<p><strong>Attention is all you need!</strong></p>
<p><strong>不需要 RNN/CNN，所需的仅为 attention，输入为 seq 输出为 seq</strong></p>
<p><img src="/2020/01/04/NLP/Transformer/transformer4.png" alt="attention"></p>
<p><img src="/2020/01/04/NLP/Transformer/transformer5.png" alt="attention"></p>
<p><img src="/2020/01/04/NLP/Transformer/transformer6.png" alt="atttention"></p>
<p>q 代表的是查询的 weight；k 代表的是被匹配的 weight，v 代表的当前位置的表示向量</p>
<p>从矩阵的并行运算来考虑整个运算过程是这样的：</p>
<p><img src="/2020/01/04/NLP/Transformer/parallel_compute_transformer.png" alt="parallel_compute_transformer"></p>
<h3 id="3-multi-head-self-attention"><a href="#3-multi-head-self-attention" class="headerlink" title="3. multi-head self-attention"></a>3. multi-head self-attention</h3><p>为什么会引入 <code>multihead self-attention</code>：</p>
<p>不同的 head 可关注不同层面的信息，以<code>2-head-self-attention</code>为例，1-head可能更关注 local 层面的信息，2-head 可能更关注 global 层面的信息。</p>
<p>多抽头的 self-attention：</p>
<p>这里对每个 a 得到多个 b_i_n 可以通过一个矩阵 transform 进行降维。</p>
<p><img src="/2020/01/04/NLP/Transformer/transformer7.png" alt="atttention"></p>
<p>从上述可以看出，上述的 seq2seq 结构并没有考虑位置信息，有点像 BOW 一样，所以针对其进行改进，考虑进位置信息 <code>self-attention</code></p>
<p>在 a_i 中加入 e_i（并不是从 data 中学习得到，人为设置）；<br>关于为何是把 e_i 直接相加，而不是 concatenate：将 e_i concatenate 上 a_i，乘上 W，经过矩阵分解运算，可以发现最终和直接加上一个vector的效果是一样的。</p>
<p><img src="/2020/01/04/NLP/Transformer/transformer8.png" alt="attention"></p>
<p>将 RNN 替换为 self-attention之后的 seq2seq model:</p>
<p><img src="/2020/01/04/NLP/Transformer/transformer9.png" alt="attention"></p>
<h3 id="4-transformer-–-Google-AI-Blog"><a href="#4-transformer-–-Google-AI-Blog" class="headerlink" title="4. transformer – Google AI Blog"></a>4. transformer – Google AI Blog</h3><ul>
<li><a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank" rel="noopener">https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html</a></li>
</ul>
<h3 id="5-常见的-translation-seq2seq-model"><a href="#5-常见的-translation-seq2seq-model" class="headerlink" title="5. 常见的 translation seq2seq model"></a>5. 常见的 translation seq2seq model</h3><p><img src="/2020/01/04/NLP/Transformer/transformer10.png" alt="seq2seq"></p>
<p>self-attention transformer encoder会将 input data 的信息看完，在 decoder 中，会看 input data 的 layer及前一个产生的 token .</p>
<p><img src="/2020/01/04/NLP/Transformer/tranformer11.png" alt="seq2seq"></p>
<h3 id="6-transformer-的常见应用"><a href="#6-transformer-的常见应用" class="headerlink" title="6. transformer 的常见应用"></a>6. transformer 的常见应用</h3><p>将传统 RNN 不能处理长的 sequence，应用到 transeformer，使其输入文章生成 wikepedia 型的sequence。</p>
<p>-reference: <a href="https://arxiv.org/pdf/1801.10198.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1801.10198.pdf</a></p>
<p><img src="/2020/01/04/NLP/Transformer/transformer12.png" alt="app"></p>
<h3 id="7-Universal-Transformer"><a href="#7-Universal-Transformer" class="headerlink" title="7. Universal Transformer"></a>7. Universal Transformer</h3><p>将 original tansformer 在时间上做 RNN，重复利用</p>
<p><img src="/2020/01/04/NLP/Transformer/transformer13.png" alt="universal"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/04/NLP/word_embedding/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/04/NLP/word_embedding/" itemprop="url">word_embedding</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-04T22:53:51+08:00">
                2020-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h1><h2 id="1-of-N-Encoding"><a href="#1-of-N-Encoding" class="headerlink" title="1-of-N Encoding"></a>1-of-N Encoding</h2><h2 id="2-Word-Embeddding"><a href="#2-Word-Embeddding" class="headerlink" title="2. Word Embeddding"></a>2. Word Embeddding</h2><ul>
<li><code>unsupervised learning</code></li>
<li><code>dimension reduction</code> wword embedding 的维度要比 1-of-N encoding 低很多</li>
</ul>
<h2 id="3-Training-的两种方法"><a href="#3-Training-的两种方法" class="headerlink" title="3. Training 的两种方法"></a>3. Training 的两种方法</h2><h3 id="3-1-Count-based"><a href="#3-1-Count-based" class="headerlink" title="3.1 Count-based"></a>3.1 Count-based</h3><p>通过计算 co-occurence frequency，并计算两个 vector 的 dot product，使其与 frequency 相似</p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_1.png" alt="word_embedding"></p>
<h3 id="3-2-Count-based-的代表"><a href="#3-2-Count-based-的代表" class="headerlink" title="3.2 Count-based 的代表"></a>3.2 Count-based 的代表</h3><h4 id="3-2-1-LSA-Latent-Semantic-Analysis"><a href="#3-2-1-LSA-Latent-Semantic-Analysis" class="headerlink" title="3.2.1 LSA(Latent Semantic Analysis)"></a>3.2.1 LSA(Latent Semantic Analysis)</h4><h4 id="3-2-2-word2vec"><a href="#3-2-2-word2vec" class="headerlink" title="3.2.2 word2vec"></a>3.2.2 word2vec</h4><h4 id="3-2-3-GloVe-Global-Vectors-for-word-representation"><a href="#3-2-3-GloVe-Global-Vectors-for-word-representation" class="headerlink" title="3.2.3 GloVe(Global Vectors for word representation)"></a>3.2.3 GloVe(Global Vectors for word representation)</h4><p><em>参考：<a href="http://www.fanyeong.com/2018/02/19/glove-in-detail/" target="_blank" rel="noopener">http://www.fanyeong.com/2018/02/19/glove-in-detail/</a></em></p>
<blockquote>
<p>它是一个基于 <code>全局词频统计</code> 的词表征（word representation）工具，它可以把一个单词表达成一个由实数组成的向量，这些向量捕捉到了单词之间的语义特性，比如：相似性（similarity）、类比性（analogy）等。我们通过对向量的运算，比如欧式距离或cosine相似度，可以计算出两个单词之间的语义相似性。</p>
</blockquote>
<h3 id="3-2-Prediction-based"><a href="#3-2-Prediction-based" class="headerlink" title="3.2 Prediction-based"></a>3.2 Prediction-based</h3><p>基于 prediction 的方法，通过学习上下文的信息来预测下一个输出，来保证下一个输出相同的输入具有相似的 input vector</p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_2.png" alt="word_embedding"></p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_3.png" alt="word_embedding"></p>
<p>上述只是考虑到了前一个词汇的 vector 输入，当输入扩展到 n 的时候，采取的方法是将 weight metrix 强制相等</p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_4.png" alt="word_embedding"></p>
<ul>
<li>如何保证 weight metrix 是相等的呢？</li>
</ul>
<p>保证每次 weight update 的时候减去相同的分量</p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_5.png" alt="word_embedding"></p>
<h3 id="3-3-Prediction-based-–-Various-Architecture"><a href="#3-3-Prediction-based-–-Various-Architecture" class="headerlink" title="3.3 Prediction-based – Various Architecture"></a>3.3 Prediction-based – Various Architecture</h3><ul>
<li>CBOW(Continuous bag of word)</li>
<li>Skip-gram</li>
</ul>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_6.png" alt="word_embedding"></p>
<h3 id="3-4-Word-Embedding-的-hidden-layer-为什么不是-deep-的"><a href="#3-4-Word-Embedding-的-hidden-layer-为什么不是-deep-的" class="headerlink" title="3.4 Word Embedding 的 hidden layer 为什么不是 deep 的"></a>3.4 Word Embedding 的 hidden layer 为什么不是 deep 的</h3><p>Tomas Mikolov</p>
<blockquote>
<p>word embeeding是个很早的概念，以前也是 deep 的做法，但是效果并不太好，Tomas 使用很多 trick ，并采用单个 hidden layer 的做法将效果训练的很好</p>
</blockquote>
<h3 id="3-5-word-vector的一些有趣的东西"><a href="#3-5-word-vector的一些有趣的东西" class="headerlink" title="3.5 word vector的一些有趣的东西"></a>3.5 word vector的一些有趣的东西</h3><p><img src="/2020/01/04/NLP/word_embedding/word_emb_7.png" alt="word_embedding"></p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_8.png" alt="word_embedding"></p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_9.png" alt="word_embedding"></p>
<h3 id="3-Document-embedding"><a href="#3-Document-embedding" class="headerlink" title="3. Document embedding"></a>3. Document embedding</h3><p><img src="/2020/01/04/NLP/word_embedding/word_emb_11.png" alt="document-embedding"></p>
<p>一种直观的想法是使用 Bag-of-word 的思路，将 word ebedding 组成 document 的 semantic，word 的位置信息也很重要</p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_12.png" alt="word_embedding"></p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_13.png" alt="word_embedding"></p>
<p><img src="/2020/01/04/NLP/word_embedding/word_emb_14.png" alt="word_embedding"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/04/NLP/%E5%AE%9E%E4%BD%93%E4%B8%8E%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%E4%B8%8E%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E7%9A%84%E8%AF%86%E5%88%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/04/NLP/%E5%AE%9E%E4%BD%93%E4%B8%8E%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%E4%B8%8E%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E7%9A%84%E8%AF%86%E5%88%AB/" itemprop="url">词性标注与命名实体的识别</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-04T22:51:03+08:00">
                2020-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/%E5%AE%9E%E4%BD%93%E4%B8%8E%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/" itemprop="url" rel="index">
                    <span itemprop="name">实体与关系抽取</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-词性标注"><a href="#1-词性标注" class="headerlink" title="1.词性标注"></a>1.词性标注</h3><p>词性标注完成的任务是对词性进行标注如动词、名词、形容词等，为下游的任务如句法分析提供预处理步骤，将数量极大的词标注到数百种的词性上。</p>
<p>目前采用的词性标注方法采用的往往和分词方法相同的一些序列标注模型，在中文词性标注中常用到的模型有：</p>
<ul>
<li>基于隐马尔科夫模型的词性标注（Hidden Markov Model）</li>
<li>基于感知机的词性标注</li>
<li>基于条件随机场的词性标注（Conditional Random Field）</li>
</ul>
<h3 id="2-命名实体的识别（Named-Entity-Recognization）"><a href="#2-命名实体的识别（Named-Entity-Recognization）" class="headerlink" title="2.命名实体的识别（Named Entity Recognization）"></a>2.命名实体的识别（Named Entity Recognization）</h3><p>命名实体的识别，是为了识别语料中的人命、地名、机构名等命名实体，往往也可采用基于规则和基于统计的模型，类似于序列标注模型</p>
<h4 id="2-1-NER的相关模型和方法"><a href="#2-1-NER的相关模型和方法" class="headerlink" title="2.1 NER的相关模型和方法"></a>2.1 NER的相关模型和方法</h4><p><img src="%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%E4%B8%8E%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/NER.png" alt="NER模型"></p>
<h4 id="2-2-常用的技术"><a href="#2-2-常用的技术" class="headerlink" title="2.2 常用的技术"></a>2.2 常用的技术</h4><p>基于规则的方法</p>
<ul>
<li>语言专家手工构造规则模板</li>
</ul>
<p>基于统计的方法</p>
<ul>
<li>隐马尔科夫模型（HMM）</li>
<li>最大熵（ME)</li>
<li>支持向量机（SVM）</li>
<li>条件随机场（CRF)</li>
</ul>
<p>基于深度学习的方法 </p>
<p><em>参考：<a href="https://zhuanlan.zhihu.com/p/43061858" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/43061858</a></em></p>
<ul>
<li>Bert-BiLSTM-CRF: <a href="https://github.com/macanv/BERT-BiLSTM-CRF-NER" target="_blank" rel="noopener">https://github.com/macanv/BERT-BiLSTM-CRF-NER</a></li>
<li>IDCNN/BiLSTM-CRF: <a href="https://github.com/crownpku/Information-Extraction-Chinese/tree/master/NER_IDCNN_CRF" target="_blank" rel="noopener">https://github.com/crownpku/Information-Extraction-Chinese/tree/master/NER_IDCNN_CRF</a></li>
<li>BiLSTM-CRF: <a href="https://github.com/Determined22/zh-NER-TF" target="_blank" rel="noopener">https://github.com/Determined22/zh-NER-TF</a></li>
</ul>
<h4 id="2-3-数据集"><a href="#2-3-数据集" class="headerlink" title="2.3 数据集"></a>2.3 数据集</h4><p>参考：<a href="https://yq.aliyun.com/articles/604048" target="_blank" rel="noopener">https://yq.aliyun.com/articles/604048</a></p>
<ul>
<li><code>CoNLL2003</code> <a href="https://www.clips.uantwerpen.be/conll2003/ner/" target="_blank" rel="noopener">https://www.clips.uantwerpen.be/conll2003/ner/</a></li>
<li>OntoNotes 5.0 / CoNNLL 2012 (<a href="https://catalog.ldc.upenn.edu/ldc2013t19" target="_blank" rel="noopener">https://catalog.ldc.upenn.edu/ldc2013t19</a>)</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/04/NLP/CORPUS/ACE_2005/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/04/NLP/CORPUS/ACE_2005/" itemprop="url">ACE_2005</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-04T22:49:36+08:00">
                2020-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/CORPUS/" itemprop="url" rel="index">
                    <span itemprop="name">CORPUS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ACE-2005-数据集详解"><a href="#ACE-2005-数据集详解" class="headerlink" title="ACE 2005 数据集详解"></a>ACE 2005 数据集详解</h1><p><code>ace_2005_td_v7_LDC2006T06</code></p>
<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><h2 id="2-事件抽取任务"><a href="#2-事件抽取任务" class="headerlink" title="2. 事件抽取任务"></a>2. 事件抽取任务</h2><ul>
<li>事件检测（Event Detection），主要是根据上下文识别出触发词以及代表的事件类型和子类型；</li>
<li>事件元素识别（Argument Detection）：事件元素是指事件的参与者。</li>
</ul>
<h2 id="3-标注类型"><a href="#3-标注类型" class="headerlink" title="3. 标注类型"></a>3. 标注类型</h2><p>ACE2005定义了8种事件类别以及33种子类别。</p>
<p><img src="/2020/01/04/NLP/CORPUS/ACE_2005/ace_2005.jpg" alt="ace_2005"></p>
<p><img src="/2020/01/04/NLP/CORPUS/ACE_2005/ACE2005_datasets.png" alt="ace_2005"></p>
<h2 id="4-文件类型分析"><a href="#4-文件类型分析" class="headerlink" title="4. 文件类型分析"></a>4. 文件类型分析</h2><h3 id="4-1-xxx-apf-xml-文件"><a href="#4-1-xxx-apf-xml-文件" class="headerlink" title="4.1 xxx.apf.xml 文件"></a>4.1 <code>xxx.apf.xml</code> 文件</h3><p>噶该文件为 <code>ACE annotation file format</code>，里面包含了多种标注：<code>entity</code>、<code>relation</code>、<code>event</code>；</p>
<h4 id="4-1-1-entity-的标注"><a href="#4-1-1-entity-的标注" class="headerlink" title="4.1.1 entity 的标注"></a>4.1.1 <code>entity</code> 的标注</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">entity</span> <span class="attr">ID</span>=<span class="string">"CNN_CF_20030303.1900.00-E1"</span> <span class="attr">TYPE</span>=<span class="string">"PER"</span> <span class="attr">SUBTYPE</span>=<span class="string">"Individual"</span> <span class="attr">CLASS</span>=<span class="string">"SPC"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">entity_mention</span> <span class="attr">ID</span>=<span class="string">"CNN_CF_20030303.1900.00-E1-2"</span> <span class="attr">TYPE</span>=<span class="string">"NOM"</span> <span class="attr">LDCTYPE</span>=<span class="string">"NOMPRE"</span> <span class="attr">LDCATR</span>=<span class="string">"TRUE"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"490"</span> <span class="attr">END</span>=<span class="string">"498"</span>&gt;</span>Secretary<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"490"</span> <span class="attr">END</span>=<span class="string">"498"</span>&gt;</span>Secretary<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">entity_mention</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">entity_mention</span> <span class="attr">ID</span>=<span class="string">"CNN_CF_20030303.1900.00-E1-14"</span> <span class="attr">TYPE</span>=<span class="string">"NAM"</span> <span class="attr">LDCTYPE</span>=<span class="string">"NAM"</span> <span class="attr">LDCATR</span>=<span class="string">"FALSE"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"754"</span> <span class="attr">END</span>=<span class="string">"793"</span>&gt;</span>Secretary of Homeland Security Tom Ridge<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"785"</span> <span class="attr">END</span>=<span class="string">"793"</span>&gt;</span>Tom Ridge<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">entity_mention</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">entity</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="4-1-2-relation-的标注"><a href="#4-1-2-relation-的标注" class="headerlink" title="4.1.2 relation 的标注"></a>4.1.2 <code>relation</code> 的标注</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">relation</span> <span class="attr">ID</span>=<span class="string">"CNN_CF_20030303.1900.00-R2"</span> <span class="attr">TYPE</span>=<span class="string">"PART-WHOLE"</span> <span class="attr">SUBTYPE</span>=<span class="string">"Geographical"</span> <span class="attr">TENSE</span>=<span class="string">"Unspecified"</span> <span class="attr">MODALITY</span>=<span class="string">"Asserted"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">relation_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E99"</span> <span class="attr">ROLE</span>=<span class="string">"Arg-1"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">relation_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E3"</span> <span class="attr">ROLE</span>=<span class="string">"Arg-2"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">relation_mention</span> <span class="attr">ID</span>=<span class="string">"CNN_CF_20030303.1900.00-R2-1"</span> <span class="attr">LEXICALCONDITION</span>=<span class="string">"Possessive"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"1873"</span> <span class="attr">END</span>=<span class="string">"1882"</span>&gt;</span>our shores<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">relation_mention_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E99-69"</span> <span class="attr">ROLE</span>=<span class="string">"Arg-1"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"1873"</span> <span class="attr">END</span>=<span class="string">"1882"</span>&gt;</span>our shores<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">relation_mention_argument</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">relation_mention_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E3-70"</span> <span class="attr">ROLE</span>=<span class="string">"Arg-2"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"1873"</span> <span class="attr">END</span>=<span class="string">"1875"</span>&gt;</span>our<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">relation_mention_argument</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">relation_mention</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">relation</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="4-1-3-event-的标注"><a href="#4-1-3-event-的标注" class="headerlink" title="4.1.3 event 的标注"></a>4.1.3 <code>event</code> 的标注</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">event</span> <span class="attr">ID</span>=<span class="string">"CNN_CF_20030303.1900.00-EV1"</span> <span class="attr">TYPE</span>=<span class="string">"Movement"</span> <span class="attr">SUBTYPE</span>=<span class="string">"Transport"</span> <span class="attr">MODALITY</span>=<span class="string">"Asserted"</span> <span class="attr">POLARITY</span>=<span class="string">"Positive"</span> <span class="attr">GENERICITY</span>=<span class="string">"Specific"</span> <span class="attr">TENSE</span>=<span class="string">"Past"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">event_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E96"</span> <span class="attr">ROLE</span>=<span class="string">"Vehicle"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">event_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E98"</span> <span class="attr">ROLE</span>=<span class="string">"Person"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">event_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E99"</span> <span class="attr">ROLE</span>=<span class="string">"Destination"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">event_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E4"</span> <span class="attr">ROLE</span>=<span class="string">"Agent"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">event_mention</span> <span class="attr">ID</span>=<span class="string">"CNN_CF_20030303.1900.00-EV1-1"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"369"</span> <span class="attr">END</span>=<span class="string">"449"</span>&gt;</span>a 30-foot Cuban patrol boat with four heavily armed men landed on</span><br><span class="line">American shores<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ldc_scope</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"277"</span> <span class="attr">END</span>=<span class="string">"514"</span>&gt;</span>Even as the</span><br><span class="line">secretary of homeland security was putting his people on high alert last</span><br><span class="line">month, a 30-foot Cuban patrol boat with four heavily armed men landed on</span><br><span class="line">American shores, utterly undetected by the Coast Guard Secretary Ridge</span><br><span class="line">now leads<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">ldc_scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">anchor</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"425"</span> <span class="attr">END</span>=<span class="string">"430"</span>&gt;</span>landed<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">anchor</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">event_mention_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E96-178"</span> <span class="attr">ROLE</span>=<span class="string">"Vehicle"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"369"</span> <span class="attr">END</span>=<span class="string">"423"</span>&gt;</span>a 30-foot Cuban patrol boat with four heavily armed men<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">event_mention_argument</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">event_mention_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E98-180"</span> <span class="attr">ROLE</span>=<span class="string">"Person"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"402"</span> <span class="attr">END</span>=<span class="string">"423"</span>&gt;</span>four heavily armed men<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">event_mention_argument</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">event_mention_argument</span> <span class="attr">REFID</span>=<span class="string">"CNN_CF_20030303.1900.00-E99-181"</span> <span class="attr">ROLE</span>=<span class="string">"Destination"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">extent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">charseq</span> <span class="attr">START</span>=<span class="string">"435"</span> <span class="attr">END</span>=<span class="string">"449"</span>&gt;</span>American shores<span class="tag">&lt;/<span class="name">charseq</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">extent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">event_mention_argument</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">event_mention</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">event</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-2-xxx-sgm-文件"><a href="#4-2-xxx-sgm-文件" class="headerlink" title="4.2 xxx.sgm 文件"></a>4.2 <code>xxx.sgm</code> 文件</h3><p><code>.sgm</code>文件为 SGM 格式的文件，其中保存的为新闻的原文</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">DOC</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">DOCID</span>&gt;</span> CNN_CF_20030303.1900.00 <span class="tag">&lt;/<span class="name">DOCID</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">DOCTYPE</span> <span class="attr">SOURCE</span>=<span class="string">"broadcast conversation"</span>&gt;</span> STORY <span class="tag">&lt;/<span class="name">DOCTYPE</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">DATETIME</span>&gt;</span> 2003-03-03T19:00:00-05:00 <span class="tag">&lt;/<span class="name">DATETIME</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">BODY</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">HEADLINE</span>&gt;</span></span><br><span class="line">New Questions About Attacking Iraq; Is Torturing Terrorists Necessary?</span><br><span class="line"><span class="tag">&lt;/<span class="name">HEADLINE</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">TEXT</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">TURN</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">SPEAKER</span>&gt;</span> BEGALA <span class="tag">&lt;/<span class="name">SPEAKER</span>&gt;</span></span><br><span class="line">Well, we'll debate that later on in the show. We'll have a couple of</span><br><span class="line">experts come out, so I'll withhold my comments until then. Even as the</span><br><span class="line">secretary of homeland security was putting his people on high alert last</span><br><span class="line">month, a 30-foot Cuban patrol boat with four heavily armed men landed on</span><br><span class="line">American shores, utterly undetected by the Coast Guard Secretary Ridge</span><br><span class="line">now leads. Now, why has our president placed homeland security in the</span><br><span class="line">hands of Republican political hacks instead of professionals, by the way?</span><br><span class="line">Attorney General John Ashcroft, for example, is a career politician. He</span><br><span class="line">lost an election to a dead man. Secretary of Homeland Security Tom Ridge</span><br><span class="line">is another career politician who was passed over by Mr. Bush for the vice</span><br><span class="line">presidency. And Deputy Secretary of Homeland Security Asa Hutchinson is</span><br><span class="line">yet another career politician and a graduate of the disgraceful Bob Jones</span><br><span class="line">University. Apparently, Mr. Bush only turns to professionals when it's</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="5-事件抽取"><a href="#5-事件抽取" class="headerlink" title="5. 事件抽取"></a>5. 事件抽取</h3><p>因为用ACE2005数据集多用来做事件抽取的任务，这里详细介绍下事件抽取相关。</p>
<p>关于 event-type 以及 event-argument 的相关，可以参考 <a href="https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-events-guidelines-v5.4.3.pdf" target="_blank" rel="noopener">ldc-document</a></p>
<h3 id="6-ACE-数据的预处理"><a href="#6-ACE-数据的预处理" class="headerlink" title="6. ACE 数据的预处理"></a>6. ACE 数据的预处理</h3>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/04/NLP/Course/%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/04/NLP/Course/%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B0/" itemprop="url">中文事件抽取综述</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-04T22:47:57+08:00">
                2020-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/Course/" itemprop="url" rel="index">
                    <span itemprop="name">Course</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="中文事件抽取技术研究"><a href="#中文事件抽取技术研究" class="headerlink" title="中文事件抽取技术研究"></a>中文事件抽取技术研究</h2><p><em>C:/Users/wangc/Desktop/newsGrid/paper/事件抽取</em></p>
<h3 id="1-Motivation"><a href="#1-Motivation" class="headerlink" title="1. Motivation"></a>1. Motivation</h3><h4 id="1-1-事件抽取的三大关键技术："><a href="#1-1-事件抽取的三大关键技术：" class="headerlink" title="1.1 事件抽取的三大关键技术："></a>1.1 事件抽取的三大关键技术：</h4><ul>
<li>EMD（Entity Mention Detection），实体识别</li>
<li>ED（Event Detection），事件的识别</li>
<li>ARP（Argument Role Prediction），论元角色的识别</li>
</ul>
<h4 id="1-2-事件抽取的方法："><a href="#1-2-事件抽取的方法：" class="headerlink" title="1.2 事件抽取的方法："></a>1.2 事件抽取的方法：</h4><ul>
<li>基于模式匹配的方法</li>
<li>基于机器学习的方法</li>
</ul>
<h4 id="1-3-基于机器学习的方法把事件抽取的任务看作分类问题，"><a href="#1-3-基于机器学习的方法把事件抽取的任务看作分类问题，" class="headerlink" title="1.3 基于机器学习的方法把事件抽取的任务看作分类问题，"></a>1.3 基于机器学习的方法把事件抽取的任务看作分类问题，</h4><blockquote>
<p>Hai Leong Chieu 和 Hwee Tou<br>Ng 于 2002 年首次在事件抽取中引入最大熵分类<br>器[9 ] ,用于事件元素的识别 ; David Ahn 2006 年结<br>合 MegaM 和 Timbl 两种机器学习方法分别实现了<br>事件抽取中事件类别识别和事件元素识别这两个主<br>要步骤 , 在 ACE 英文语料上均取得了不错的效<br>果[4 ] 。 但 Ahn 的方法由于将每个词作为一个实例<br>来训练机器学习模型 ,引入了大量的反例 ,导致正反<br>例严重不平衡 ;此外 ,事件类别的多元分类以及为每<br>类事件元素单独构造多元分类器在语料规模较小的<br>时候存在着一定的数据稀疏问题 。</p>
</blockquote>
<h3 id="2-Method"><a href="#2-Method" class="headerlink" title="2. Method"></a>2. Method</h3><blockquote>
<p>本文提出一种基于触发<br>词扩展和二元分类相结合的识别方法进行事件类别<br>的识别 ,多元分类模型的方法进行事件元素的识别 ,<br>较好的避免了正反例不平衡和数据稀疏问题 。</p>
</blockquote>
<p><strong>keywords: 基于触发词扩展和二元分类的事件识别，多元分类用于事件元素识别</strong></p>
<h4 id="2-1-系统架构图"><a href="#2-1-系统架构图" class="headerlink" title="2.1 系统架构图"></a>2.1 系统架构图</h4><p><img src="/2020/01/04/NLP/Course/%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B0/Paper_%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B01.png" alt="系统架构图"></p>
<h4 id="2-2-事件类别的识别"><a href="#2-2-事件类别的识别" class="headerlink" title="2.2 事件类别的识别"></a>2.2 事件类别的识别</h4><p>a. 通过对句子的分词查看扩充之后的触发词表，并对每一个候选事件划定一个候选事件类别的范围；</p>
<p>b. 通过将候选事件类别识别看作一个二元分类的问题，判断是否为满足候选类别的事件；<br><img src="/2020/01/04/NLP/Course/%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B0/Paper_%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B02.png" alt="特征描述"></p>
<h4 id="2-3-事件元素的识别"><a href="#2-3-事件元素的识别" class="headerlink" title="2.3 事件元素的识别"></a>2.3 事件元素的识别</h4><p>将事件元素的识别任务看成分类问题，转换为对文本中每个候选元素进行类别标签的识别，再进行挑选</p>
<p>a. 三种多元分类的策略</p>
<p><img src="/2020/01/04/NLP/Course/%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B0/Paper_%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B03.png" alt="分类策略"></p>
<p>b. 特征的选取</p>
<p><img src="/2020/01/04/NLP/Course/%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B0/Paper_%E4%B8%AD%E6%96%87%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E7%BB%BC%E8%BF%B04.png" alt="分类特征"></p>
<h3 id="3-Performance"><a href="#3-Performance" class="headerlink" title="3. Performance"></a>3. Performance</h3><p>使用 ACE 2005 中文语料作为实验数据，使用 F值的评价方法进行评测。</p>
<h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>这篇文章采用的是对事件识别和事件论元识别的分类方法，一种典型的 Pipe Model，在模型的改进方面并没有多大的创新。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wanncy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笔记记录">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/" itemprop="url">新闻推荐系统_武楚涵</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-04T22:46:06+08:00">
                2020-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/Course/" itemprop="url" rel="index">
                    <span itemprop="name">Course</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="新闻推荐"><a href="#新闻推荐" class="headerlink" title="新闻推荐"></a>新闻推荐</h1><p><em>清华大学武楚涵博士</em></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu01.jpg" alt="wu_01"></p>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu02.jpg" alt="wu_02"></p>
<ol>
<li>Google News Personalization: Scalable Online Collaborative Filtering”, WWW’07, pp. 271-280, 2007.</li>
</ol>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu03.jpg" alt="wu_03"></p>
<ol>
<li>Jeong Woo Son, A.-Yeong Kim, Seong-Bae Park:<br>A location-based news article recommendation with explicit localized semantic analysis. SIGIR 2013: 293-302</li>
<li>Trapit Bansal, Mrinal Kanti Das, Chiranjib Bhattacharyya:<br>Content Driven User Profiling for Comment-Worthy Recommendations of News and Blog Articles. RecSys 2015: 195-202</li>
<li>Jianxun Lian, Fuzheng Zhang, Xing Xie, Guangzhong Sun:<br>Towards Better Representation Learning for Personalized News Recommendation: a Multi-Channel Deep Fusion Approach. IJCAI 2018: 3805-3811</li>
</ol>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu04.jpg" alt="wu_04"></p>
<ol>
<li>Shumpei Okura, Yukihiro Tagami, Shingo Ono, Akira Tajima:<br>Embedding-based News Recommendation for Millions of Users. 1933-1942</li>
</ol>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu05.jpg" alt="wu_05"></p>
<ol>
<li>Hongwei Wang, Fuzheng Zhang, Xing Xie, Minyi Guo:<br>DKN: Deep Knowledge-Aware Network for News Recommendation. WWW 2018: 1835-1844</li>
</ol>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu06.jpg" alt="wu_06"></p>
<ol>
<li>Qiannan Zhu, Xiaofei Zhou, Zeliang Song, Jianlong Tan, Li Guo:<br>DAN: Deep Attention Neural Network for News Recommendation. AAAI 2019: 5973-5980</li>
</ol>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu07.jpg" alt="wu_07"></p>
<ol>
<li>Dhruv Khattar, Vaibhav Kumar, Vasudeva Varma, Manish Gupta:<br>Weave&amp;Rec: A Word Embedding based 3-D Convolutional Network for News Recommendation. CIKM 2018: 1855-1858</li>
</ol>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu08.jpg" alt="wu_08"></p>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu09.jpg" alt="wu_09"></p>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu10.jpg" alt="wu_10"></p>
<p><img src="/2020/01/04/NLP/Course/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E6%AD%A6%E6%A5%9A%E6%B6%B5/wu11.jpg" alt="wu_11"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/8/">&lt;i class=&quot;fa fa-angle-left&quot;&gt;&lt;&#x2F;i&gt;</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/29/">29</a><a class="extend next" rel="next" href="/page/10/">&lt;i class=&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="wanncy" />
            
              <p class="site-author-name" itemprop="name">wanncy</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">282</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">69</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">67</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/wangda1" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wanncy</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        




  <script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=66562237";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
